---
title: "Exercise 1"
author: "Luis E Borrero"
date: "8/29/2019"
output: html_document
---

# C-1 Exercise 1 
First, we need to install the readr package to make sure that the read_delim() function works. We also need to install the janitor package to get the cleaned up data in a more easily redeable format. We must call them with library() to make sure they are working in our file. We then bring up the data from GitHub using the read_delim() for txt. formatted data. This way each column contains one of the variables, and there
are 365 rows, representing each day of the year in 2013. They are arranged in order, with January
1st (20130101) on the 1st row, and December 31st (20131231) on the last row.
```{r}
library(readr)
library(janitor)
shd.wx <- janitor::clean_names(read_delim("https://raw.githubusercontent.com/NicoleRadziwill/Data-for-R-Examples/master/kshd-2013.txt", delim="\t1") )
shd.wx
```

We first analytically compute the slope, using the follwing formula: the correlation coefficient between the dew point and temperature data (as specified by $) times the standard deviation of the dewpoint divided by the standard deviation of the temperature. We use the following functions: cor() and sd().
```{r}
slope <- cor(shd.wx$dewp, shd.wx$temp) * ( sd(shd.wx$dewp)/sd(shd.wx$temp) )
slope
```

We then analytically compute the y intercept by calculating the difference between the mean of the dewpoint minues the slope times the mean of the temperature. 
```{r}
intercept <- mean(shd.wx$dewp) - (slope*mean(shd.wx$temp))
intercept
```

With this, the line of best fit should be y = 1.107x - 18.05. We then create the fit variable based on the linear model, using lm() and specifying that the dependent variable is dewpoint and the independent variable is the temperature. We separate both with ~. This reads as following, "create a variable fit that
contains all of the information R has computed about the equation of the best fit line, and how
it relates to all of the data points, constructing a linear model of dewpoint by temperature." We also use the resid() fucntion to get the residuals of the linear model, and store them in shd.wx$residuals. 
```{r}
fit <- lm(shd.wx$dewp ~ shd.wx$temp)
shd.wx$residuals <- resid(fit)
```

We can then use the summary() function to see if the linear model we got analytically is the same as the one generated by R. We can see that the intercept is -18.05264 and the slope is 1.10742, meaning that our equation is e y = 1.107x - 18.05, i.e. the same as before. 
```{r}
summary(fit)
```

Making sure we have installed ggplot2, we then plot the corresponding scatterplot of the Dewpoint versus the Temperature (on the left) and the Residuals scatterplot on the right. For this we use the ggplot() function and the various specifications like dewp on y axis and temp on x-axis on the first graph, and residuals on y-axis and temperature on x-axis on the second graph, the respective titles, the line of best fit based on our equation, and the left to right grid using cowplot. 
```{r}
library(ggplot2)
left <- shd.wx %>% ggplot(aes(x=temp, y=dewp)) + geom_point() + geom_smooth(aes(color="red"), se=FALSE, method="lm") + ggtitle("Dewpoint vs. Temperature") + theme(legend.position="none")
right <- shd.wx %>% ggplot(aes(x=temp, y=residuals)) + geom_point() + geom_hline(yintercept=0) + ggtitle("Residuals")
cowplot::plot_grid(left,right)
```

To make sure that the linear model we chose is correct we must make sure that there is a balanced number of residuals above and below the zero line, there is not a pattern in our residuals (i.e. lack independence) and thus they should be randomly scattered above and below the best fit line, if the residuals plot looks like a scatterplot with strong positive or negative correlation then it may signify that the linear fit has a bias, i.e. we are over or underpredicting our line, and finally if the line is heteroscedastic or not, i.e. the variance of a variable is unequal across the range of values of a second variable that predicts it. If our model fits these assumptions, then using a linear model is appropriate. Since this is the case here, the equation for our line of best fit is y = 1.107x - 18.053.

We then calculate the coefficient of determination, which is the correlation coefficient squared. To calculate the latter we use the cor() function to see the correlation between the dewpoint and temperature variable. 
```{r}
cor(shd.wx$dewp, shd.wx$temp)
```

We then multiply the result by itself, i.e. square it and get the coefficient of determination. In this case, it is: 0.9047053, meaning that 90.47% of variability in our data is explained by the linear fit, and 9.53% of the variability is contained in the residuals. 
```{r}
.95116*.95116
```

We can access the same value of R-squared with the following statement, i.e. calcualte the the r.squared of the fit variable. 
```{r}
summary(fit)$r.squared
```

To further evaluate the goodness of our linear model we can generate four plots and see if it is appropriate. We us plot() to plot this model; we use par() to set our graph's parameters and combine the graphs. 
```{r}
par(mfrow=c(2,2))
plot(fit)
```

First, we can see that the the residuals randomly scattered around zero and not see any patterns in this plot. 

Second (top right), the residuals are normally distributed, meaning that all of our observations show up along the diagonal line. 

Third (bottom left), the variance is consistent across the entire range of my x values, that is our data is not heteroscedastic.

Fourth (bottom right), there are no influential points in the dataset that overwhelmingly influence the characteristics of the regression line.

# C-1 Exercise 2

Best fit lines are used to predict values of y for a given value of x, but we must be careful since we do not want to predict values of y for values of x that are  outside the bounds of the original data. For instance, consider a simple dataset where x is a particular woman's age, and y is the total number of children she had at that particular age. Here, we can use lm() to generate a new fit to predict the number of kids by (~) age. We can generate a scatterplot, and place the line of best fit on the graph, uwing the following code. We first input the age of the woman and the number of kids she had a those ages, and based on that create a linear model with number of kids as the dependent variable and the age of the woman as the independent variable. Then we calculate the residuals of new.fit. 
```{r}
df <- data.frame(age=c(21,24,25,32), number.of.kids=c(1,2,4,5)) 
new.fit <- lm(df$number.of.kids ~ df$age) 
df$residuals <- resid(new.fit)
```

With this information we can then plot the resulting graphs as we did before with ggplot and put them in the same grid. The left graph is the scatterplot with the number of kids in the y-axis and age on the x-axis , and the second one graphing the residuals, on y-axis, and the age on x-axis as well. 
```{r}
left <- df %>% ggplot(aes(x=age, y=number.of.kids)) + geom_point(size=5) + geom_smooth(aes(color="red"), se=FALSE, method="lm") + ggtitle("# of Kids by Mother's Age at Birth") + theme(legend.position="none")

right <- df %>% ggplot(aes(x=age, y=residuals)) + geom_point() + geom_hline(yintercept=0) + ggtitle("Residuals")

cowplot::plot_grid(left,right)
```

We can then get the summary of the new.fit and see that 81.38% of the variability in the data is explained by the model, and that resulting best fit line equation is  = 0.3538x - 6.0231. Theoretically, we can use this equation to to predict how many children she should have by the time she reaches any age.
```{r}
summary(new.fit)
```

For instance, when she reaches 50, the model predicts that she will have around 12 children. However, this is considered extrapolating because we've gone beyond the bounds of the original independent variable, since we do not have data beyond the age of 32. Besides, it is not even realistic for women to have children at 50. Thus, this prediction does not work. 
```{r}
x <- 50
y <- (0.3538)*(x) - 6.0231 
y
```

